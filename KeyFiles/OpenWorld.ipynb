{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Open-World Experiment\n",
        "\n"
      ],
      "metadata": {
        "id": "3mB1AOjQG8bt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 준비\n",
        "1. 데이터 업로드\n",
        "    - mon_standard.pkl\n",
        "    - X3_mon_data.pkl\n",
        "    - X4_mon_data.pkl\n",
        "2. 파일 경로 설정\n",
        "    - 데이터를 업로드한 위치의 경로를 path 변수에 할당\n"
      ],
      "metadata": {
        "id": "LVt7yq_fG3v6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vzSqxAoUeLrQ"
      },
      "outputs": [],
      "source": [
        "# 파일 경로 설정\n",
        "path = '/content/drive/MyDrive/24-2/ML'\n",
        "mon_file = f'{path}/mon_standard.pkl'\n",
        "unmon_file = f'{path}/unmon_standard10.pkl'\n",
        "X3_mon_file = f'{path}/X3_mon_data.pkl'\n",
        "X4_mon_file = f'{path}/X4_mon_data.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDF_eQdfIxq"
      },
      "source": [
        "## Categorical Features extraction\n",
        "categorical_feature.ipynb 파일의 내용과 겹칩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9rA8o91EfHvI"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "# 설정\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS_MON = 950  # Monitored 데이터 URL 수\n",
        "TOTAL_URLS_UNMON = 3000  # Unmonitored 데이터 URL 수\n",
        "\n",
        "# Number of Incoming/Outgoing Packets\n",
        "def count_in_out_packets(data):\n",
        "    num_incoming = sum(1 for c in data if c > 0)  # Positive indicates incoming\n",
        "    num_outgoing = sum(1 for c in data if c < 0)  # Negative indicates outgoing\n",
        "    return num_incoming, num_outgoing\n",
        "\n",
        "# Number of Incoming/Outgoing Packets as a Fraction of Total\n",
        "def fraction_in_out_packets(num_incoming, num_outgoing):\n",
        "    total_packets = num_incoming + num_outgoing\n",
        "    if total_packets == 0:  # To avoid division by zero\n",
        "        return 0, 0\n",
        "    fraction_incoming = num_incoming / total_packets\n",
        "    fraction_outgoing = num_outgoing / total_packets\n",
        "    return fraction_incoming, fraction_outgoing\n",
        "\n",
        "\n",
        "# Standard Deviation of Outgoing Packet Ordering List\n",
        "def std_dev_outgoing_packets(data):\n",
        "    outgoing_sizes = [abs(c) * 512 for c in data if c < 0]  # Only outgoing packets\n",
        "    if len(outgoing_sizes) > 1:\n",
        "        return np.std(outgoing_sizes)\n",
        "    return 0\n",
        "\n",
        "\n",
        "# Sum of All Items in the Alternative Concentration Feature List\n",
        "def sum_alternative_concentration(size_seq):\n",
        "    return sum(size_seq)\n",
        "\n",
        "\n",
        "# Average of the Outgoing and Total Number of Packets\n",
        "def avg_outgoing_and_total_packets(num_incoming, num_outgoing):\n",
        "    total_packets = num_incoming + num_outgoing\n",
        "    if total_packets == 0:  # To avoid division by zero\n",
        "        return 0\n",
        "    avg = (num_outgoing + total_packets) / 2\n",
        "    return avg\n",
        "\n",
        "\n",
        "# Sum of Incoming, Outgoing, and Total Number of Packets\n",
        "def sum_in_out_total_packets(num_incoming, num_outgoing):\n",
        "    return num_incoming + num_outgoing\n",
        "\n",
        "\n",
        "# Sum of Alternative Number of Packets per Second\n",
        "def sum_packets_per_second(time_seq, size_seq):\n",
        "    total_time = sum(time_seq)\n",
        "    if total_time == 0:\n",
        "        return 0\n",
        "    total_packets = sum(size_seq)\n",
        "    return total_packets / total_time\n",
        "\n",
        "# Total Number of Packets\n",
        "def total_packets(num_incoming, num_outgoing):\n",
        "    return num_incoming + num_outgoing\n",
        "\n",
        "# 데이터 로드\n",
        "with open(mon_file, 'rb') as f:\n",
        "    mon_data = pickle.load(f)\n",
        "with open(unmon_file, 'rb') as f:\n",
        "    unmon_data = pickle.load(f)\n",
        "\n",
        "# Monitored 데이터 변환\n",
        "X1_mon, X2_mon, X3_mon, X4_mon, X5_mon, X6_mon, X7_mon, X8_mon, X9_mon, y_mon = [], [], [], [], [], [], [], [], [], []\n",
        "\n",
        "# For monitored data\n",
        "for i in range(TOTAL_URLS_MON):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE\n",
        "\n",
        "    for sample in mon_data[i]:\n",
        "        size_seq = []\n",
        "        time_seq = []\n",
        "\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1\n",
        "            time_seq.append(abs(c))\n",
        "            size_seq.append(dr * 512)\n",
        "\n",
        "        num_incoming, num_outgoing = count_in_out_packets(sample)\n",
        "        fraction_incoming, fraction_outgoing = fraction_in_out_packets(num_incoming, num_outgoing)\n",
        "        std_dev_outgoing = std_dev_outgoing_packets(sample)\n",
        "        sum_alternative = sum_alternative_concentration(size_seq)\n",
        "        avg_outgoing_total = avg_outgoing_and_total_packets(num_incoming, num_outgoing)\n",
        "        sum_in_out_total = sum_in_out_total_packets(num_incoming, num_outgoing)\n",
        "        sum_per_second = sum_packets_per_second(time_seq, size_seq)\n",
        "        total = total_packets(num_incoming, num_outgoing)\n",
        "\n",
        "        # Store all features in respective lists\n",
        "        X1_mon.append(time_seq)\n",
        "        X2_mon.append(size_seq)\n",
        "        X5_mon.append(fraction_incoming)\n",
        "        X6_mon.append(fraction_outgoing)\n",
        "        X7_mon.append(std_dev_outgoing)\n",
        "        X8_mon.append(sum_alternative)\n",
        "        X9_mon.append(avg_outgoing_total)\n",
        "        y_mon.append(label)\n",
        "\n",
        "with open(X3_mon_file, 'rb') as f_x3:\n",
        "    X3_mon = pickle.load(f_x3)\n",
        "\n",
        "with open(X4_mon_file, 'rb') as f_x4:\n",
        "    X4_mon = pickle.load(f_x4)\n",
        "\n",
        "X1_unmon, X2_unmon, X3_unmon, X4_unmon, X5_unmon, X6_unmon, X7_unmon, X8_unmon, X9_unmon = [], [], [], [], [], [], [], [], []\n",
        "\n",
        "# For unmonitored data\n",
        "for i in range(TOTAL_URLS_UNMON):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "\n",
        "    for c in unmon_data[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512)\n",
        "\n",
        "    num_incoming, num_outgoing = count_in_out_packets(unmon_data[i])\n",
        "    fraction_incoming, fraction_outgoing = fraction_in_out_packets(num_incoming, num_outgoing)\n",
        "    std_dev_outgoing = std_dev_outgoing_packets(unmon_data[i])\n",
        "    sum_alternative = sum_alternative_concentration(size_seq)\n",
        "    avg_outgoing_total = avg_outgoing_and_total_packets(num_incoming, num_outgoing)\n",
        "    sum_in_out_total = sum_in_out_total_packets(num_incoming, num_outgoing)\n",
        "    sum_per_second = sum_packets_per_second(time_seq, size_seq)\n",
        "    total = total_packets(num_incoming, num_outgoing)\n",
        "\n",
        "    # Store all features in respective lists\n",
        "    X1_unmon.append(time_seq)\n",
        "    X2_unmon.append(size_seq)\n",
        "    X5_unmon.append(fraction_incoming)\n",
        "    X6_unmon.append(fraction_outgoing)\n",
        "    X7_unmon.append(std_dev_outgoing)\n",
        "    X8_unmon.append(sum_alternative)\n",
        "    X9_unmon.append(avg_outgoing_total)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc3KTOsMyYCz"
      },
      "source": [
        "### Extracting X3_unmon, X4_unmon\n",
        "- Use X2_unmon.\n",
        "- Check X3_unmon, X4_unmon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gr5VS12kyKud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96b5170-95cf-45f0-e122-857d78751e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 로드 및 준비 완료!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# Function to calculate X3 (Cumulative Packet Sizes)\n",
        "def compute_cumulative_sizes(X2_unmon):\n",
        "    return [np.cumsum(seq).tolist() for seq in X2_unmon]\n",
        "\n",
        "# Function to calculate X4 (Bursts)\n",
        "def compute_bursts(X2_unmon):\n",
        "    bursts = []\n",
        "    for seq in X2_unmon:\n",
        "        current_burst = 0\n",
        "        burst_sequence = []\n",
        "        for i, value in enumerate(seq):\n",
        "            if i == 0 or np.sign(value) == np.sign(seq[i - 1]):\n",
        "                current_burst += value\n",
        "            else:\n",
        "                burst_sequence.append(current_burst)\n",
        "                current_burst = value\n",
        "        burst_sequence.append(current_burst)  # Append the last burst\n",
        "        bursts.append(burst_sequence)\n",
        "    return bursts\n",
        "\n",
        "# Extract X3 and X4\n",
        "X3_unmon = compute_cumulative_sizes(X2_unmon)\n",
        "X4_unmon = compute_bursts(X2_unmon)\n",
        "\n",
        "# Monitored와 Unmonitored 데이터를 Pandas 데이터프레임으로 변환\n",
        "mon_df = pd.DataFrame({\n",
        "    'Fraction Incoming (X5)': X5_mon,\n",
        "    'Fraction Outgoing (X6)': X6_mon,\n",
        "    'Std Dev Outgoing (X7)': X7_mon,\n",
        "    'Sum Alternative (X8)': X8_mon,\n",
        "    'Average Outgoing & Total (X9)': X9_mon,\n",
        "    'Label': ['Monitored'] * len(X5_mon)\n",
        "})\n",
        "\n",
        "unmon_df = pd.DataFrame({\n",
        "    'Fraction Incoming (X5)': X5_unmon,\n",
        "    'Fraction Outgoing (X6)': X6_unmon,\n",
        "    'Std Dev Outgoing (X7)': X7_unmon,\n",
        "    'Sum Alternative (X8)': X8_unmon,\n",
        "    'Average Outgoing & Total (X9)': X9_unmon,\n",
        "    'Label': ['Unmonitored'] * len(X5_unmon)\n",
        "})\n",
        "\n",
        "# 데이터 병합\n",
        "data = pd.concat([mon_df, unmon_df], ignore_index=True)\n",
        "print(\"데이터 로드 및 준비 완료!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 학습 및 실험 수행\n",
        "1) Binary Classification: Determine whether the web traffic trace corresponds to a monitored website.   \n",
        "\n",
        " To do this, reassign the label '1' to all monitored website instances (positive samples) and assign the label '-1' to all unmonitored website instances (negative samples). Train and test the model in this binary setting.\n",
        "\n",
        "2) Multi-Class Classification: Classify 95 monitored website traces with unique labels against additional unmonitored websites.\n",
        "\n",
        "   In the multi-class setting, label the monitored website instances with {0, 1, 2, ..., 94} and the unmonitored website instances with the label '-1'.\n"
      ],
      "metadata": {
        "id": "bfYiEKGrk3HF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "o84SnLfNLp06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 리스트 형식의 X1~X4 요약해서 사용"
      ],
      "metadata": {
        "id": "WJ_At2Ruok2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 리스트 데이터를 요약하는 함수 (평균, 표준편차, 최대값, 최소값, 합계 등 사용 가능)\n",
        "def summarize_features(data):\n",
        "    return {\n",
        "        'mean': np.mean(data) if len(data) > 0 else 0,\n",
        "        'std': np.std(data) if len(data) > 0 else 0,\n",
        "        'max': np.max(data) if len(data) > 0 else 0,\n",
        "        'min': np.min(data) if len(data) > 0 else 0,\n",
        "        'sum': np.sum(data)\n",
        "    }\n",
        "\n",
        "# Monitored 데이터 요약\n",
        "mon_features = pd.DataFrame({\n",
        "    'X1_mean': [summarize_features(seq)['mean'] for seq in X1_mon],\n",
        "    'X1_std': [summarize_features(seq)['std'] for seq in X1_mon],\n",
        "    'X1_max': [summarize_features(seq)['max'] for seq in X1_mon],\n",
        "    'X2_mean': [summarize_features(seq)['mean'] for seq in X2_mon],\n",
        "    'X2_std': [summarize_features(seq)['std'] for seq in X2_mon],\n",
        "    'X2_max': [summarize_features(seq)['max'] for seq in X2_mon],\n",
        "    'X3_mean': [summarize_features(seq)['mean'] for seq in X3_mon],\n",
        "    'X3_std': [summarize_features(seq)['std'] for seq in X3_mon],\n",
        "    'X3_max': [summarize_features(seq)['max'] for seq in X3_mon],\n",
        "    'X4_mean': [summarize_features(seq)['mean'] for seq in X4_mon],\n",
        "    'X4_std': [summarize_features(seq)['std'] for seq in X4_mon],\n",
        "    'X4_max': [summarize_features(seq)['max'] for seq in X4_mon],\n",
        "    'X5': X5_mon,\n",
        "    'X6': X6_mon,\n",
        "    'X7': X7_mon,\n",
        "    'X8': X8_mon,\n",
        "    'X9': X9_mon,\n",
        "    'Label': 1  # Monitored는 1\n",
        "})\n",
        "\n",
        "# Unmonitored 데이터 요약\n",
        "unmon_features = pd.DataFrame({\n",
        "    'X1_mean': [summarize_features(seq)['mean'] for seq in X1_unmon],\n",
        "    'X1_std': [summarize_features(seq)['std'] for seq in X1_unmon],\n",
        "    'X1_max': [summarize_features(seq)['max'] for seq in X1_unmon],\n",
        "    'X2_mean': [summarize_features(seq)['mean'] for seq in X2_unmon],\n",
        "    'X2_std': [summarize_features(seq)['std'] for seq in X2_unmon],\n",
        "    'X2_max': [summarize_features(seq)['max'] for seq in X2_unmon],\n",
        "    'X3_mean': [summarize_features(seq)['mean'] for seq in X3_unmon],\n",
        "    'X3_std': [summarize_features(seq)['std'] for seq in X3_unmon],\n",
        "    'X3_max': [summarize_features(seq)['max'] for seq in X3_unmon],\n",
        "    'X4_mean': [summarize_features(seq)['mean'] for seq in X4_unmon],\n",
        "    'X4_std': [summarize_features(seq)['std'] for seq in X4_unmon],\n",
        "    'X4_max': [summarize_features(seq)['max'] for seq in X4_unmon],\n",
        "    'X5': X5_unmon,\n",
        "    'X6': X6_unmon,\n",
        "    'X7': X7_unmon,\n",
        "    'X8': X8_unmon,\n",
        "    'X9': X9_unmon,\n",
        "    'Label': -1  # Unmonitored는 -1\n",
        "})\n",
        "\n",
        "# Binary와 Multi-Class 데이터 생성\n",
        "binary_data = pd.concat([mon_features, unmon_features], ignore_index=True)\n",
        "multi_data = binary_data.copy()\n",
        "\n",
        "# Multi-Class Label 설정\n",
        "multi_data.loc[:len(mon_features)-1, 'Label'] = np.repeat(range(95), len(mon_features) // 95)\n",
        "\n",
        "# Binary Classification: 데이터 분리\n",
        "X_bin = binary_data.drop('Label', axis=1)\n",
        "y_bin = binary_data['Label']\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=0)\n",
        "\n",
        "# Multi-Class Classification: 데이터 분리\n",
        "X_multi = multi_data.drop('Label', axis=1)\n",
        "y_multi = multi_data['Label']\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=0)\n",
        "\n",
        "# 데이터 표준화\n",
        "scaler_bin = StandardScaler()\n",
        "X_train_bin = scaler_bin.fit_transform(X_train_bin)\n",
        "X_test_bin = scaler_bin.transform(X_test_bin)\n",
        "\n",
        "scaler_multi = StandardScaler()\n",
        "X_train_multi = scaler_multi.fit_transform(X_train_multi)\n",
        "X_test_multi = scaler_multi.transform(X_test_multi)\n",
        "\n",
        "# SVM 모델 생성 및 학습\n",
        "# Binary Classification\n",
        "svm_bin = SVC(kernel='rbf', C=1, gamma='scale', random_state=0)\n",
        "svm_bin.fit(X_train_bin, y_train_bin)\n",
        "\n",
        "# Multi-Class Classification\n",
        "svm_multi = SVC(kernel='rbf', C=1, gamma='scale', decision_function_shape='ovr', random_state=0)\n",
        "svm_multi.fit(X_train_multi, y_train_multi)\n",
        "\n",
        "# 평가\n",
        "# Binary Classification 결과\n",
        "y_pred_bin = svm_bin.predict(X_test_bin)\n",
        "print(\"Binary Classification Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
        "print(\"Binary Classification Report:\")\n",
        "print(classification_report(y_test_bin, y_pred_bin))\n",
        "\n",
        "# Multi-Class Classification 결과\n",
        "y_pred_multi = svm_multi.predict(X_test_multi)\n",
        "print(\"Multi-Class Classification Accuracy:\", accuracy_score(y_test_multi, y_pred_multi))\n",
        "print(\"Multi-Class Classification Report:\")\n",
        "print(classification_report(y_test_multi, y_pred_multi))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfCsW8AJo_1q",
        "outputId": "6ceef0b1-7f5b-4f51-a443-ea9870866ae8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Classification Accuracy: 0.9211363636363636\n",
            "Binary Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.99      0.43      0.60       609\n",
            "           1       0.92      1.00      0.96      3791\n",
            "\n",
            "    accuracy                           0.92      4400\n",
            "   macro avg       0.95      0.72      0.78      4400\n",
            "weighted avg       0.93      0.92      0.91      4400\n",
            "\n",
            "Multi-Class Classification Accuracy: 0.3640909090909091\n",
            "Multi-Class Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.22      0.82      0.35       609\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.33      0.24      0.28        46\n",
            "           2       0.00      0.00      0.00        43\n",
            "           3       0.00      0.00      0.00        47\n",
            "           4       0.10      0.05      0.06        43\n",
            "           5       0.70      0.35      0.47        40\n",
            "           6       0.42      0.76      0.54        29\n",
            "           7       0.67      0.35      0.46        52\n",
            "           8       0.85      0.27      0.41        41\n",
            "           9       0.20      0.02      0.04        41\n",
            "          10       0.79      0.23      0.35        48\n",
            "          11       0.82      0.41      0.55        44\n",
            "          12       0.64      0.64      0.64        36\n",
            "          13       0.00      0.00      0.00        43\n",
            "          14       0.00      0.00      0.00        24\n",
            "          15       0.36      0.28      0.32        32\n",
            "          16       0.79      0.65      0.71        40\n",
            "          17       0.00      0.00      0.00        42\n",
            "          18       0.69      0.45      0.55        20\n",
            "          19       0.66      0.74      0.70        42\n",
            "          20       0.61      0.75      0.67        40\n",
            "          21       0.75      0.23      0.35        40\n",
            "          22       0.43      0.10      0.16        31\n",
            "          23       0.00      0.00      0.00        44\n",
            "          24       0.16      0.27      0.20        41\n",
            "          25       0.00      0.00      0.00        41\n",
            "          26       0.42      0.56      0.48        36\n",
            "          27       0.67      0.26      0.38        38\n",
            "          28       1.00      0.04      0.08        48\n",
            "          29       0.73      0.41      0.52        54\n",
            "          30       0.44      0.45      0.45        44\n",
            "          31       0.00      0.00      0.00        45\n",
            "          32       0.64      0.42      0.51        33\n",
            "          33       0.79      0.61      0.69        51\n",
            "          34       0.50      0.09      0.15        34\n",
            "          35       0.00      0.00      0.00        43\n",
            "          36       0.11      0.07      0.09        28\n",
            "          37       0.00      0.00      0.00        48\n",
            "          38       0.45      0.51      0.48        41\n",
            "          39       0.77      0.49      0.60        41\n",
            "          40       1.00      0.06      0.11        33\n",
            "          41       0.34      0.48      0.40        48\n",
            "          42       0.00      0.00      0.00        45\n",
            "          43       0.47      0.53      0.50        36\n",
            "          44       0.56      0.86      0.68        37\n",
            "          45       0.29      0.30      0.29        33\n",
            "          46       0.00      0.00      0.00        37\n",
            "          47       1.00      0.02      0.05        41\n",
            "          48       0.19      0.07      0.10        44\n",
            "          49       0.00      0.00      0.00        39\n",
            "          50       0.55      0.59      0.57        39\n",
            "          51       0.75      0.29      0.41        42\n",
            "          52       1.00      0.02      0.04        44\n",
            "          53       0.57      0.56      0.57        41\n",
            "          54       1.00      0.02      0.05        43\n",
            "          55       0.50      0.07      0.12        46\n",
            "          56       0.00      0.00      0.00        30\n",
            "          57       0.65      0.40      0.49        43\n",
            "          58       0.32      0.48      0.38        25\n",
            "          59       0.68      0.81      0.74        42\n",
            "          60       0.67      0.05      0.09        42\n",
            "          61       1.00      0.04      0.09        45\n",
            "          62       0.40      0.40      0.40        35\n",
            "          63       0.00      0.00      0.00        39\n",
            "          64       0.69      0.51      0.59        43\n",
            "          65       0.54      0.32      0.40        44\n",
            "          66       0.45      0.60      0.51        42\n",
            "          67       0.75      0.59      0.66        41\n",
            "          68       0.60      0.13      0.22        45\n",
            "          69       0.33      0.17      0.22        42\n",
            "          70       0.63      0.97      0.77        34\n",
            "          71       0.00      0.00      0.00        50\n",
            "          72       0.00      0.00      0.00        46\n",
            "          73       0.49      0.66      0.56        35\n",
            "          74       0.40      0.50      0.45        42\n",
            "          75       0.63      0.65      0.64        48\n",
            "          76       0.54      0.78      0.64        36\n",
            "          77       0.25      0.03      0.05        40\n",
            "          78       0.00      0.00      0.00        31\n",
            "          79       0.29      0.33      0.31        42\n",
            "          80       0.38      0.72      0.50        39\n",
            "          81       0.67      0.06      0.11        35\n",
            "          82       0.60      0.45      0.52        33\n",
            "          83       0.06      0.03      0.04        33\n",
            "          84       0.61      0.41      0.49        46\n",
            "          85       0.64      0.66      0.65        35\n",
            "          86       0.64      0.81      0.72        36\n",
            "          87       0.64      0.27      0.38        33\n",
            "          88       0.36      0.22      0.27        41\n",
            "          89       0.45      0.37      0.41        41\n",
            "          90       0.46      0.50      0.48        36\n",
            "          91       0.62      0.21      0.31        38\n",
            "          92       0.00      0.00      0.00        43\n",
            "          93       0.65      0.54      0.59        37\n",
            "          94       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.36      4400\n",
            "   macro avg       0.44      0.30      0.31      4400\n",
            "weighted avg       0.41      0.36      0.31      4400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2)리스트 형식의 X1~X4 제외하고 X5부터 사용"
      ],
      "metadata": {
        "id": "ej8zg40To1U4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Feature와 Target 준비\n",
        "# X1~X9 모두 사용 (리스트들을 열로 변환)\n",
        "mon_features = pd.DataFrame({\n",
        "    'X5': X5_mon, 'X6': X6_mon, 'X7': X7_mon, 'X8': X8_mon, 'X9': X9_mon\n",
        "})\n",
        "unmon_features = pd.DataFrame({\n",
        "    'X5': X5_unmon, 'X6': X6_unmon, 'X7': X7_unmon, 'X8': X8_unmon, 'X9': X9_unmon\n",
        "})\n",
        "\n",
        "# Binary Classification Label (Monitored: 1, Unmonitored: -1)\n",
        "mon_features['Label'] = 1\n",
        "unmon_features['Label'] = -1\n",
        "\n",
        "# Multi-Class Classification Label (Monitored: 0~94, Unmonitored: -1)\n",
        "mon_features_multi = mon_features.copy()\n",
        "mon_features_multi['Label'] = np.repeat(range(95), len(mon_features) // 95)\n",
        "unmon_features_multi = unmon_features.copy()\n",
        "unmon_features_multi['Label'] = -1\n",
        "\n",
        "# 2. 데이터 결합\n",
        "binary_data = pd.concat([mon_features, unmon_features], ignore_index=True)\n",
        "multi_data = pd.concat([mon_features_multi, unmon_features_multi], ignore_index=True)\n",
        "\n",
        "# 3. 데이터 정규화 및 Train/Test Split\n",
        "def preprocess_data(data):\n",
        "    X = data.drop(columns=['Label']).values  # Features\n",
        "    y = data['Label'].values  # Labels\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "# Binary 데이터 전처리\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = preprocess_data(binary_data)\n",
        "\n",
        "# Multi-Class 데이터 전처리\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = preprocess_data(multi_data)\n",
        "\n",
        "# 4. SVM 모델 학습 및 평가\n",
        "def train_and_evaluate_svm(X_train, X_test, y_train, y_test, task_name=\"Task\"):\n",
        "    svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=0)\n",
        "    svm.fit(X_train, y_train)\n",
        "    y_pred = svm.predict(X_test)\n",
        "    print(f\"=== {task_name} ===\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print()\n",
        "\n",
        "# Binary Classification\n",
        "train_and_evaluate_svm(X_train_bin, X_test_bin, y_train_bin, y_test_bin, \"Binary Classification (Open-World)\")\n",
        "\n",
        "# Multi-Class Classification\n",
        "train_and_evaluate_svm(X_train_multi, X_test_multi, y_train_multi, y_test_multi, \"Multi-Class Classification (Open-World)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi43JU0WmYe6",
        "outputId": "6881b67b-6d19-429f-f22d-2544d4fc1856"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Binary Classification (Open-World) ===\n",
            "Accuracy: 86.18%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.00      0.00       609\n",
            "           1       0.86      1.00      0.93      3791\n",
            "\n",
            "    accuracy                           0.86      4400\n",
            "   macro avg       0.93      0.50      0.46      4400\n",
            "weighted avg       0.88      0.86      0.80      4400\n",
            "\n",
            "Confusion Matrix:\n",
            "[[   1  608]\n",
            " [   0 3791]]\n",
            "\n",
            "=== Multi-Class Classification (Open-World) ===\n",
            "Accuracy: 19.57%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.15      0.87      0.25       609\n",
            "           0       0.00      0.00      0.00        40\n",
            "           1       0.00      0.00      0.00        46\n",
            "           2       0.00      0.00      0.00        43\n",
            "           3       0.00      0.00      0.00        47\n",
            "           4       0.00      0.00      0.00        43\n",
            "           5       0.00      0.00      0.00        40\n",
            "           6       0.00      0.00      0.00        29\n",
            "           7       0.00      0.00      0.00        52\n",
            "           8       0.00      0.00      0.00        41\n",
            "           9       0.00      0.00      0.00        41\n",
            "          10       0.00      0.00      0.00        48\n",
            "          11       0.81      0.39      0.52        44\n",
            "          12       0.55      0.61      0.58        36\n",
            "          13       0.00      0.00      0.00        43\n",
            "          14       0.00      0.00      0.00        24\n",
            "          15       0.00      0.00      0.00        32\n",
            "          16       0.64      0.17      0.27        40\n",
            "          17       0.00      0.00      0.00        42\n",
            "          18       0.00      0.00      0.00        20\n",
            "          19       0.00      0.00      0.00        42\n",
            "          20       0.50      0.72      0.59        40\n",
            "          21       0.00      0.00      0.00        40\n",
            "          22       0.00      0.00      0.00        31\n",
            "          23       0.00      0.00      0.00        44\n",
            "          24       0.08      0.15      0.11        41\n",
            "          25       0.00      0.00      0.00        41\n",
            "          26       0.00      0.00      0.00        36\n",
            "          27       0.00      0.00      0.00        38\n",
            "          28       1.00      0.02      0.04        48\n",
            "          29       0.00      0.00      0.00        54\n",
            "          30       0.33      0.50      0.40        44\n",
            "          31       0.00      0.00      0.00        45\n",
            "          32       0.00      0.00      0.00        33\n",
            "          33       0.32      0.35      0.34        51\n",
            "          34       0.00      0.00      0.00        34\n",
            "          35       0.00      0.00      0.00        43\n",
            "          36       0.00      0.00      0.00        28\n",
            "          37       0.00      0.00      0.00        48\n",
            "          38       0.00      0.00      0.00        41\n",
            "          39       0.00      0.00      0.00        41\n",
            "          40       0.00      0.00      0.00        33\n",
            "          41       0.00      0.00      0.00        48\n",
            "          42       0.00      0.00      0.00        45\n",
            "          43       0.00      0.00      0.00        36\n",
            "          44       0.52      0.92      0.67        37\n",
            "          45       0.00      0.00      0.00        33\n",
            "          46       0.00      0.00      0.00        37\n",
            "          47       0.00      0.00      0.00        41\n",
            "          48       0.00      0.00      0.00        44\n",
            "          49       0.00      0.00      0.00        39\n",
            "          50       0.00      0.00      0.00        39\n",
            "          51       0.00      0.00      0.00        42\n",
            "          52       0.00      0.00      0.00        44\n",
            "          53       0.00      0.00      0.00        41\n",
            "          54       0.00      0.00      0.00        43\n",
            "          55       0.67      0.04      0.08        46\n",
            "          56       0.00      0.00      0.00        30\n",
            "          57       0.33      0.05      0.08        43\n",
            "          58       0.00      0.00      0.00        25\n",
            "          59       0.00      0.00      0.00        42\n",
            "          60       0.00      0.00      0.00        42\n",
            "          61       0.00      0.00      0.00        45\n",
            "          62       0.50      0.03      0.05        35\n",
            "          63       0.00      0.00      0.00        39\n",
            "          64       0.48      0.33      0.39        43\n",
            "          65       0.00      0.00      0.00        44\n",
            "          66       0.00      0.00      0.00        42\n",
            "          67       0.00      0.00      0.00        41\n",
            "          68       0.50      0.04      0.08        45\n",
            "          69       0.00      0.00      0.00        42\n",
            "          70       0.48      0.88      0.62        34\n",
            "          71       0.00      0.00      0.00        50\n",
            "          72       0.00      0.00      0.00        46\n",
            "          73       0.00      0.00      0.00        35\n",
            "          74       0.27      0.26      0.27        42\n",
            "          75       0.80      0.25      0.38        48\n",
            "          76       0.41      0.78      0.54        36\n",
            "          77       0.00      0.00      0.00        40\n",
            "          78       0.00      0.00      0.00        31\n",
            "          79       0.00      0.00      0.00        42\n",
            "          80       0.00      0.00      0.00        39\n",
            "          81       0.00      0.00      0.00        35\n",
            "          82       0.54      0.42      0.47        33\n",
            "          83       0.00      0.00      0.00        33\n",
            "          84       0.00      0.00      0.00        46\n",
            "          85       0.62      0.23      0.33        35\n",
            "          86       0.53      0.28      0.36        36\n",
            "          87       0.19      0.21      0.20        33\n",
            "          88       0.00      0.00      0.00        41\n",
            "          89       0.41      0.37      0.38        41\n",
            "          90       0.39      0.36      0.38        36\n",
            "          91       0.27      0.21      0.24        38\n",
            "          92       0.00      0.00      0.00        43\n",
            "          93       0.00      0.00      0.00        37\n",
            "          94       0.00      0.00      0.00        41\n",
            "\n",
            "    accuracy                           0.20      4400\n",
            "   macro avg       0.13      0.10      0.09      4400\n",
            "weighted avg       0.13      0.20      0.11      4400\n",
            "\n",
            "Confusion Matrix:\n",
            "[[528   0   0 ...   0   0   0]\n",
            " [ 40   0   0 ...   0   0   0]\n",
            " [ 44   0   0 ...   0   0   0]\n",
            " ...\n",
            " [ 39   0   0 ...   0   0   0]\n",
            " [ 33   0   0 ...   0   0   0]\n",
            " [ 40   0   0 ...   0   0   0]]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RF"
      ],
      "metadata": {
        "id": "17UAZV7QtKyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. 데이터 준비\n",
        "# 'Label' 컬럼을 포함하여, 'X'는 피처들, 'y'는 라벨로 설정\n",
        "X = pd.concat([mon_features[['X5', 'X6', 'X7', 'X8', 'X9']], unmon_features[['X5', 'X6', 'X7', 'X8', 'X9']]], ignore_index=True)\n",
        "y = pd.concat([mon_features['Label'], unmon_features['Label']], ignore_index=True)\n",
        "\n",
        "# 2. 데이터 분할 (80% 훈련, 20% 테스트)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# 3. Random Forest 모델 생성 및 학습\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 4. 예측\n",
        "y_pred_bin = rf_classifier.predict(X_test)\n",
        "\n",
        "# 5. 성능 평가 (Binary Classification)\n",
        "print(\"=== Binary Classification (Monitored vs. Unmonitored) ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_bin):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_bin))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_bin))\n",
        "\n",
        "# === Multi-Class Classification (Monitored Classes) ===\n",
        "# 여기서는 Multi-Class Classification을 위해 'Label'을 각각의 Monitored 클래스별로 다르게 설정했다고 가정\n",
        "# Multi-Class 모델을 위한 예시로 'Label'이 Monitored에서 다른 범주들을 가지게 설정\n",
        "y_multi = y  # 여기에 Multi-Class 라벨을 추가하는 부분 (기존 'Label' 컬럼을 사용)\n",
        "\n",
        "# Multi-Class 분할\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X, y_multi, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Multi-Class Random Forest 모델 학습\n",
        "rf_classifier_multi = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "rf_classifier_multi.fit(X_train_multi, y_train_multi)\n",
        "\n",
        "# 7. Multi-Class 예측\n",
        "y_pred_multi = rf_classifier_multi.predict(X_test_multi)\n",
        "\n",
        "# 8. 성능 평가 (Multi-Class Classification)\n",
        "print(\"\\n=== Multi-Class Classification (Monitored Classes) ===\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test_multi, y_pred_multi):.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_multi, y_pred_multi))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test_multi, y_pred_multi))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdqOpMmPo5Bm",
        "outputId": "b743c3e0-35ad-4b1f-d804-51cc54517366"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Binary Classification (Monitored vs. Unmonitored) ===\n",
            "Accuracy: 0.8607\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.49      0.12      0.20       609\n",
            "           1       0.87      0.98      0.92      3791\n",
            "\n",
            "    accuracy                           0.86      4400\n",
            "   macro avg       0.68      0.55      0.56      4400\n",
            "weighted avg       0.82      0.86      0.82      4400\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  75  534]\n",
            " [  79 3712]]\n",
            "\n",
            "=== Multi-Class Classification (Monitored Classes) ===\n",
            "Accuracy: 0.8636\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.47      0.12      0.19       590\n",
            "           1       0.88      0.98      0.93      3810\n",
            "\n",
            "    accuracy                           0.86      4400\n",
            "   macro avg       0.67      0.55      0.56      4400\n",
            "weighted avg       0.82      0.86      0.83      4400\n",
            "\n",
            "Confusion Matrix:\n",
            "[[  69  521]\n",
            " [  79 3731]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}